%! suppress = MissingLabel
\documentclass[11pt]{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[a4paper,top=2cm,bottom=2cm,left=2cm,right=2cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{tikz}
\usetikzlibrary{arrows.meta}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}[definition]{Theorem}
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand{\A}{\mathbf{A}}
\newcommand{\x}{\mathbf{x}}

\title{Compressed sensing}
\author{Anastasiia Storozhenko}

\begin{document}
\maketitle

\textbf{Outline:}

\begin{enumerate}
    \item Introducing the problem
    \item Minimal number of measurements for 0-norm?
    \item From 0-norm to 1-norm + questions to answer
    \item When $l_1$-minimization solves the $l_0$-minimization problem (null space property)
    \item Number of measurements with log + my plots
    \item Phase transition + my plots
    \item Conclusion
\end{enumerate}

\section{Introduction}
We want to recover the sparse vector $\mathbf{x} \in \mathbb{K}^N$ knowing the vector of $m$ measurements $\mathbf{y} \in \mathbb{K}^m$ and the measurement matrix $\mathbf{A} \in M_{m \times N}(\mathbb{K})$ with $m < N$.

Applications

\section{Studying the $l_0$-minimization}

We are looking for the sparsest solution of the underdetermined system of equations $\mathbf{Ax=y}$.
One way to approach this is to solve the corresponding $l_0$-minimization problem.

\begin{definition}
    The \textbf{support} of a vector $\mathbf{x} \in \mathbb{K}^N$ is the set of indices of its nonzero entries:
    \begin{equation*}
        \mathrm{supp}(\mathbf{x}) = \{ j \in [\![1,N]\!] \colon x_j \neq 0 \}
    \end{equation*}
\end{definition}

\begin{definition}
    We define $\norm{\mathbf{x}}_0$ as the cardinality of $\mathrm{supp}(\mathbf{x})$.
    We say that the vector $\mathbf{x}$ is \textbf{$s$-sparse} if $\norm{\mathbf{x}}_0 \leq s$.
\end{definition}
Note that $\norm{\cdot}_0$ is not an actual norm, nor is it a semi-norm.
Now we can formalize the problem in the following form:
\begin{equation}\label{eq:l0}
    \mathrm{minimize} \ \norm{x}_0 \ \ \mathrm{subject\ to} \ \ \mathbf{Ax=y}. \tag{P_0}
\end{equation}

\begin{theorem}
    Let $\mathbf{A} \in M_{m \times N}(\mathbb{K})$  and $\mathbf{x}, \mathbf{z} \in \mathbb{K}^N$.
    The following statements are equivalent:

    \begin{enumerate}[label=(\roman*)]
        \item \label{itm:itm1} If $\mathbf{Ax = Az}$ and both $\x$ and $\mathbf{z}$ are $s$-sparse, then $\mathbf{x = z}$, i.e.,
        if there exists a solution for the problem \ref{eq:l0}, then it is unique.
        \item $\mathrm{Ker} \A \cap \{ \mathbf{z} \in \mathbb{K}^N \colon \norm{\mathbf{z}}_0 \leq 2s \} = \{ \mathbf{0} \}$,
        i.e., $\mathbf{0}$ is the only $s$-sparse vector in the $\mathrm{Ker} \A$.
        \item
        \item \label{itm:itm4} Every set of $2s$ columns of $\A$ is linearly independent, i.e., $\mathrm{rang} \A \geq 2s$.
    \end{enumerate}
\end{theorem}

Then most useful implication here is between statements \ref{itm:itm4} and \ref{itm:itm1}.
The matrix rank is limited by its smallest dimension, which in this case is the number of rows $m$.
From this we conclude that if $m \geq 2s$ then the problem \ref{eq:l0} has a unique solution.

NP-hardness


\section{Convex alternatives}
$\norm{\cdot}_p$: (preferably with pictures of unit balls)
\begin{itemize}
    \item $0 < p < 1$: non-convex, NP, bad
    \item $p > 1$: convex, but doesn't solve the problem in general
    \item $p = 1$: convex, solves the problem, good
\end{itemize}

\begin{figure}

\begin{tikzpicture}[>=Stealth]
   \foreach \i in {0,...,2}{
     \begin{scope}[xshift=\i*5.6cm]
      \draw [gray, densely dashed][->] (-2,0)--(3,0);
      \draw [gray, densely dashed][->] (0,-2)--(0,2.5);
      \draw [teal][shorten <=-1.5cm, shorten >=-3mm] (0,1.5)--(2.5,0) node [sloped, pos=0.75, above=-0.1cm] {$\mathbf{Ax=y}$};
    \end{scope}
   }
   \begin{scope}
       \begin{scope}
           \draw [domain=0:90,samples=100,smooth,variable=\t] plot({-1.5*cos(\t)^(3)},{1.5*sin(\t)^(3)});
           \draw [domain=0:90,samples=100,smooth,variable=\t] plot({-1.5*cos(\t)^(3)},{-1.5*sin(\t)^(3)});
           \draw [domain=0:90,samples=100,smooth,variable=\t] plot({1.5*cos(\t)^(3)},{-1.5*sin(\t)^(3)});
           \draw [domain=0:90,samples=100,smooth,variable=\t] plot({1.5*cos(\t)^(3)},{1.5*sin(\t)^(3)});
       \end{scope}
       \draw [xshift=5.6cm] (-1.5,0)--(0,1.5)--(1.5,0)--(0,-1.5)--cycle;
       \draw [](11.2,0) circle (1.28cm);

       \foreach \i [count=\j from 0] in {(0,1.5),(0,1.5), (.64,1.11)} \scoped [xshift=\j*5.6cm] { \draw[black] [-{Circle[width=3pt, length=3pt, fill=black, black]},
           shorten >=-1.5pt] (0,0) node{}  -- \i node [above right] {$x^*$} ; };

       \draw (0, -2.5) node {$p < 1$}
       \draw (5.6, -2.5) node {$p = 1$}
       \draw (11.2, -2.5) node {$p > 1$}
   \end{scope}

\end{tikzpicture}\end{figure}


basis pursuit:
\begin{equation}
    \mathrm{minimize} \ \norm{x}_1 \ \ \mathrm{subject\ to} \ \ \mathbf{Ax=y}
\end{equation}

Other algorithms from chapter 3?

\section{Studying the $l_1$-minimization}

When does it solve the problem \ref{eq:l0}? $\xrightarrow{}$ chapter 4

\begin{definition}
    Null-space property
\end{definition}

Stability and robustness?

\section{Number of measurements for $l_1$-minimization}

Proposition 3.10 from The Convex Geometry of Linear Inverse Problems.
My plots

\section{Transition phase}

Leaving on the Edge paper

\newpage


\end{document}